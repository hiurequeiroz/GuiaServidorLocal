# ü§ñ Chatbot de IA Local - Rede Comunit√°ria Portal Sem Porteiras

Um chatbot de intelig√™ncia artificial que roda localmente na rede comunit√°ria, sem necessidade de internet externa. Desenvolvido para a **Rede Comunit√°ria Portal Sem Porteiras**.

![Interface do Chatbot IA Local](printpage.png)

## üåê Configura√ß√£o de Rede

Este projeto utiliza a vari√°vel de ambiente **OLLAMA_HOST** para definir o endere√ßo do servidor Ollama:
- **Padr√£o:** `http://localhost:11434` (ideal para rodar tudo na mesma m√°quina)
- **Para usar outro servidor na rede:** edite o arquivo `.env` e defina `OLLAMA_HOST` para o IP desejado, por exemplo: `http://10.208.173.206:11434`

> Exemplo de `.env`:
> ```
> OLLAMA_HOST=http://localhost:11434
> ```
> Ou para servidor remoto:
> ```
> OLLAMA_HOST=http://10.208.173.206:11434
> ```

**Sempre copie `.env.example` para `.env` e ajuste conforme seu ambiente!**

## ‚ú® Funcionalidades

- **IA Local**: Processamento local sem depend√™ncia de servi√ßos externos
- **Acelera√ß√£o GPU**: Suporte a GPU NVIDIA para processamento mais r√°pido
- **Upload de PDFs**: Fa√ßa upload de documentos PDF para que a IA responda baseada no conte√∫do
- **M√∫ltiplos Modelos**: Suporte a diferentes modelos de IA (LLaMA 2, Mistral, Code Llama)
- **Interface Web**: Interface moderna e responsiva
- **Hist√≥rico**: Salva e exporta conversas
- **Cache Inteligente**: Cache de PDFs processados para melhor performance

## üöÄ Instala√ß√£o R√°pida

### Pr√©-requisitos

- **Sistema**: Debian 12 ou Ubuntu 22.04+
- **GPU**: NVIDIA RTX 4060 ou superior (recomendado)
- **RAM**: M√≠nimo 8GB, recomendado 16GB+
- **Armazenamento**: 20GB livres para modelos e cache
- **Docker e Docker Compose**: Instalados
- **Acesso √† rede local**: 10.208.173.206

### Deploy Autom√°tico

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-repo/ia-local.git
cd ia-local

# Deploy inteligente (detecta mudan√ßas automaticamente)
chmod +x deploy.sh
./deploy.sh
```

### Verificar Status

```bash
# Status dos containers
docker-compose ps

# Logs em tempo real
docker-compose logs -f chatbot

# Testar conectividade com servidor Ollama
curl http://10.208.173.206:11434/api/tags
```

## üîß Desenvolvimento

### Setup do Ambiente

```bash
# Configurar ambiente de desenvolvimento
chmod +x setup_dev.sh
./setup_dev.sh

# Executar em modo desenvolvimento
chmod +x run_dev.sh
./run_dev.sh
```

### Estrutura do Projeto

```
ia-local/
‚îú‚îÄ‚îÄ app.py                 # Aplica√ß√£o principal Flask
‚îú‚îÄ‚îÄ pdf_processor.py       # Processamento de PDFs
‚îú‚îÄ‚îÄ templates/             # Templates HTML
‚îú‚îÄ‚îÄ static/                # CSS, JS, imagens
‚îú‚îÄ‚îÄ uploads/               # PDFs enviados pelos usu√°rios
‚îú‚îÄ‚îÄ cache/                 # Cache de processamento
‚îú‚îÄ‚îÄ logs/                  # Logs da aplica√ß√£o
‚îú‚îÄ‚îÄ docker-compose.yml     # Configura√ß√£o Docker produ√ß√£o
‚îú‚îÄ‚îÄ docker-compose.dev.yml # Configura√ß√£o Docker desenvolvimento
‚îú‚îÄ‚îÄ deploy.sh              # Script de deploy inteligente
‚îî‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
```

## üìö Funcionalidades

### Chat com IA
- Interface web amig√°vel
- Integra√ß√£o com modelo llama2 via Ollama
- Respostas r√°pidas usando GPU RTX 4060

### Upload e Processamento de PDFs
- Upload de m√∫ltiplos PDFs
- Extra√ß√£o de texto usando PyPDF2 e pdfplumber
- Uso do conte√∫do como contexto para o chat
- Listagem e remo√ß√£o de PDFs

### Interface Administrativa
- Gerenciamento de PDFs
- Logs de sistema
- Status de conectividade

## üîó Conectividade

### Servidor Ollama Remoto
- **URL**: `http://10.208.173.206:11434`
- **Modelo**: llama2
- **GPU**: RTX 4060 (no servidor remoto)

### Interface Web
- **URL**: `http://localhost:8080`
- **Porta**: 8080
- **Acesso**: Rede local

## üìä Performance

### M√©tricas com GPU RTX 4060
- **Tempo de resposta**: 2-5 segundos
- **Utiliza√ß√£o de mem√≥ria**: ~6GB VRAM
- **Temperatura**: 45-55¬∞C
- **Throughput**: ~15-20 tokens/segundo

### Compara√ß√£o CPU vs GPU
- **CPU (antes)**: 30-60 segundos por resposta
- **GPU (agora)**: 2-5 segundos por resposta
- **Melhoria**: 10-15x mais r√°pido

## üõ†Ô∏è Comandos √öteis

### Docker
```bash
# Deploy inteligente
./deploy.sh

# Parar containers
docker-compose down

# Rebuild completo
docker-compose build --no-cache

# Ver logs
docker-compose logs -f chatbot

# Reiniciar apenas o chatbot
docker-compose restart chatbot
```

### Desenvolvimento
```bash
# Setup inicial
./setup_dev.sh

# Executar em desenvolvimento
./run_dev.sh

# Ativar ambiente virtual
source venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt
```

### Monitoramento
```bash
# Status do sistema
docker-compose ps

# Uso de recursos
docker stats

# Logs do sistema
tail -f logs/app.log

# Testar API
curl http://localhost:8080/api/health
```

## üîç Troubleshooting

### Problemas de Conectividade
```bash
# Verificar se servidor Ollama est√° acess√≠vel
curl http://10.208.173.206:11434/api/tags

# Verificar rede local
ping 10.208.173.206

# Verificar porta
telnet 10.208.173.206 11434
```

### Problemas de Performance
```bash
# Verificar uso de GPU no servidor remoto
nvidia-smi

# Verificar logs do Ollama
docker-compose logs ollama

# Verificar conectividade de rede
iperf3 -c 10.208.173.206
```

### Problemas de Deploy
```bash
# Limpar cache Docker
docker system prune -a

# Rebuild completo
docker-compose build --no-cache

# Verificar espa√ßo em disco
df -h

# Verificar permiss√µes
ls -la
```

## üìù Logs e Monitoramento

### Logs da Aplica√ß√£o
- **Localiza√ß√£o**: `logs/app.log`
- **N√≠vel**: INFO, ERROR, DEBUG
- **Rota√ß√£o**: Autom√°tica

### Logs do Docker
```bash
# Logs do chatbot
docker-compose logs chatbot

# Logs do servidor Ollama (remoto)
# Verificar no servidor 10.208.173.206
```

### M√©tricas de Performance
- **Tempo de resposta**: Monitorado automaticamente
- **Uso de recursos**: Via Docker stats
- **Erros**: Logs estruturados

## üîí Seguran√ßa

### Rede Local
- Acesso restrito √† rede local
- Sem exposi√ß√£o √† internet
- Comunica√ß√£o criptografada (se configurado)

### Uploads
- Valida√ß√£o de tipos de arquivo
- Limite de tamanho configur√°vel
- Sanitiza√ß√£o de conte√∫do

## ü§ù Contribui√ß√£o

### Para a Rede Comunit√°ria
1. Teste as funcionalidades
2. Reporte bugs ou melhorias
3. Sugira novos recursos
4. Ajude na documenta√ß√£o

### Desenvolvimento
1. Fork do reposit√≥rio
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìû Suporte

### Rede Comunit√°ria Portal Sem Porteiras
- **Grupo**: [Link do grupo]
- **Canal**: [Link do canal]
- **Email**: [Email de contato]

### Documenta√ß√£o Adicional
- [PERFORMANCE.md](PERFORMANCE.md) - An√°lise detalhada de performance
- [PDF_FEATURE.md](PDF_FEATURE.md) - Documenta√ß√£o da funcionalidade de PDFs
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - Guia de solu√ß√£o de problemas

---

**Portal Sem Porteiras** - Rede Comunit√°ria Local
*IA Local para Todos* ü§ñüåê

## üìÑ Funcionalidade de PDF

### Como Usar

1. **Upload de PDF**: Clique no bot√£o "Upload PDF" no painel lateral
2. **Sele√ß√£o**: Arraste um arquivo PDF ou clique para selecionar
3. **Processamento**: O sistema extrai automaticamente o texto do PDF
4. **Ativa√ß√£o**: Clique em um PDF na lista para ativ√°-lo como contexto
5. **Chat**: A IA responder√° baseada no conte√∫do do PDF ativo

### Recursos

- **Extra√ß√£o Inteligente**: Usa m√∫ltiplos m√©todos para extrair texto (PyPDF2 + pdfplumber)
- **Cache**: PDFs processados s√£o cacheados para evitar reprocessamento
- **Metadados**: Extrai t√≠tulo, autor, n√∫mero de p√°ginas e outras informa√ß√µes
- **Limite de Tamanho**: M√°ximo 16MB por arquivo
- **Contexto Limitado**: Limita o contexto enviado para a IA (2000 caracteres)

### Formatos Suportados

- ‚úÖ PDFs com texto (recomendado)
- ‚úÖ PDFs escaneados (OCR b√°sico)
- ‚úÖ PDFs com imagens e tabelas

## üéØ Casos de Uso

### Para Redes Comunit√°rias

1. **Documenta√ß√£o Local**: Upload de manuais, regulamentos e documentos da comunidade
2. **Educa√ß√£o**: Material did√°tico e apostilas para cursos locais
3. **Administra√ß√£o**: Processamento de formul√°rios e relat√≥rios
4. **Pesquisa**: An√°lise de documentos hist√≥ricos da comunidade

### Exemplos Pr√°ticos

- **Manual da Rede**: "Como configurar um novo n√≥ na rede?"
- **Regulamento**: "Quais s√£o as regras para uso do servidor?"
- **Relat√≥rio**: "Resuma os principais pontos do relat√≥rio mensal"
- **Apostila**: "Explique o conceito de roteamento em redes"

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# .env
OLLAMA_HOST=http://localhost:11434
MODEL_NAME=llama2
```

### Modelos Dispon√≠veis

- **llama2**: Modelo geral (padr√£o)
- **mistral**: Modelo mais r√°pido e eficiente
- **codellama**: Especializado em c√≥digo
- **llama2:13b**: Vers√£o maior e mais precisa

### Baixar Novos Modelos

1. Acesse a interface web
2. Selecione o modelo desejado no dropdown
3. Clique em "Baixar Modelo"
4. Aguarde o download (pode demorar alguns minutos)

## üõ†Ô∏è Manuten√ß√£o

### Logs

```bash
# Ver logs do chatbot
docker-compose logs chatbot

# Ver logs do Ollama
docker-compose logs ollama

# Logs de chat
tail -f logs/chat_history.json
```

### Backup

```bash
# Backup dos modelos
sudo docker run --rm -v ollama_data:/root/.ollama -v $(pwd):/backup alpine tar czf /backup/ollama-models-$(date +%Y%m%d).tar.gz -C /root/.ollama .

# Backup de PDFs e cache
tar czf backup-pdfs-$(date +%Y%m%d).tar.gz uploads/ cache/
```

### Limpeza

```bash
# Limpar cache de PDFs
rm -rf cache/*

# Limpar uploads
rm -rf uploads/*

# Limpar logs antigos
find logs/ -name "*.json" -mtime +30 -delete
```

## üîç Troubleshooting

### Problemas Comuns

1. **GPU n√£o detectada**:
   ```bash
   nvidia-smi  # Verificar se GPU est√° funcionando
   sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
   ```

2. **Modelo n√£o baixa**:
   ```bash
   # Verificar espa√ßo em disco
   df -h
   
   # Verificar logs do Ollama
   docker-compose logs ollama
   ```

3. **PDF n√£o processa**:
   ```bash
   # Verificar depend√™ncias
   docker-compose exec chatbot pip list | grep -E "(PyPDF2|pdfplumber)"
   
   # Verificar logs
   docker-compose logs chatbot
   ```

4. **Interface n√£o carrega**:
   ```bash
   # Verificar se porta est√° livre
   netstat -tlnp | grep 8080
   
   # Reiniciar servi√ßos
   docker-compose restart
   ```

### Logs Detalhados

```bash
# Ativar logs detalhados
docker-compose up -d --build
docker-compose logs -f chatbot
```

## ü§ù Contribui√ß√£o

Para contribuir com o projeto:

1. Fork o reposit√≥rio
2. Crie uma branch para sua feature
3. Fa√ßa commit das mudan√ßas
4. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üôè Agradecimentos

- **Ollama**: Framework de IA local
- **Flask**: Framework web
- **NVIDIA**: Suporte a GPU
- **Comunidade Portal Sem Porteiras**: Testes e feedback

## üìû Suporte

Para suporte t√©cnico ou d√∫vidas:

- **Email**: suporte@portalsemporteiras.org
- **Telegram**: @portalsemporteiras
- **Issues**: GitHub Issues

---

**Desenvolvido com ‚ù§Ô∏è para a Rede Comunit√°ria Portal Sem Porteiras** 