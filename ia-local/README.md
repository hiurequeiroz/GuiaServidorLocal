# ü§ñ Chatbot de IA Local - Rede Comunit√°ria Portal Sem Porteiras

Um chatbot de intelig√™ncia artificial que roda localmente na rede comunit√°ria, sem necessidade de internet externa. Desenvolvido para a **Rede Comunit√°ria Portal Sem Porteiras**.

## ‚ú® Funcionalidades

- **IA Local**: Processamento local sem depend√™ncia de servi√ßos externos
- **Acelera√ß√£o GPU**: Suporte a GPU NVIDIA para processamento mais r√°pido
- **Upload de PDFs**: Fa√ßa upload de documentos PDF para que a IA responda baseada no conte√∫do
- **M√∫ltiplos Modelos**: Suporte a diferentes modelos de IA (LLaMA 2, Mistral, Code Llama)
- **Interface Web**: Interface moderna e responsiva
- **Hist√≥rico**: Salva e exporta conversas
- **Cache Inteligente**: Cache de PDFs processados para melhor performance

## üöÄ Instala√ß√£o R√°pida

### Pr√©-requisitos

- **Sistema**: Debian 12 ou Ubuntu 22.04+
- **GPU**: NVIDIA RTX 4060 ou superior (recomendado)
- **RAM**: M√≠nimo 8GB, recomendado 16GB+
- **Armazenamento**: 20GB livres para modelos e cache

### Instala√ß√£o Autom√°tica

```bash
# Baixar script de instala√ß√£o
wget https://raw.githubusercontent.com/seu-repo/ia-local/main/install-debian.sh

# Tornar execut√°vel
chmod +x install-debian.sh

# Executar instala√ß√£o
sudo ./install-debian.sh
```

### Instala√ß√£o Manual

1. **Instalar Docker e NVIDIA Container Toolkit**:
```bash
# Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

2. **Clonar e executar**:
```bash
git clone https://github.com/seu-repo/ia-local.git
cd ia-local
sudo docker-compose up -d
```

## üìÑ Funcionalidade de PDF

### Como Usar

1. **Upload de PDF**: Clique no bot√£o "Upload PDF" no painel lateral
2. **Sele√ß√£o**: Arraste um arquivo PDF ou clique para selecionar
3. **Processamento**: O sistema extrai automaticamente o texto do PDF
4. **Ativa√ß√£o**: Clique em um PDF na lista para ativ√°-lo como contexto
5. **Chat**: A IA responder√° baseada no conte√∫do do PDF ativo

### Recursos

- **Extra√ß√£o Inteligente**: Usa m√∫ltiplos m√©todos para extrair texto (PyPDF2 + pdfplumber)
- **Cache**: PDFs processados s√£o cacheados para evitar reprocessamento
- **Metadados**: Extrai t√≠tulo, autor, n√∫mero de p√°ginas e outras informa√ß√µes
- **Limite de Tamanho**: M√°ximo 16MB por arquivo
- **Contexto Limitado**: Limita o contexto enviado para a IA (2000 caracteres)

### Formatos Suportados

- ‚úÖ PDFs com texto (recomendado)
- ‚úÖ PDFs escaneados (OCR b√°sico)
- ‚úÖ PDFs com imagens e tabelas

## üéØ Casos de Uso

### Para Redes Comunit√°rias

1. **Documenta√ß√£o Local**: Upload de manuais, regulamentos e documentos da comunidade
2. **Educa√ß√£o**: Material did√°tico e apostilas para cursos locais
3. **Administra√ß√£o**: Processamento de formul√°rios e relat√≥rios
4. **Pesquisa**: An√°lise de documentos hist√≥ricos da comunidade

### Exemplos Pr√°ticos

- **Manual da Rede**: "Como configurar um novo n√≥ na rede?"
- **Regulamento**: "Quais s√£o as regras para uso do servidor?"
- **Relat√≥rio**: "Resuma os principais pontos do relat√≥rio mensal"
- **Apostila**: "Explique o conceito de roteamento em redes"

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# .env
OLLAMA_HOST=http://localhost:11434
MODEL_NAME=llama2
```

### Modelos Dispon√≠veis

- **llama2**: Modelo geral (padr√£o)
- **mistral**: Modelo mais r√°pido e eficiente
- **codellama**: Especializado em c√≥digo
- **llama2:13b**: Vers√£o maior e mais precisa

### Baixar Novos Modelos

1. Acesse a interface web
2. Selecione o modelo desejado no dropdown
3. Clique em "Baixar Modelo"
4. Aguarde o download (pode demorar alguns minutos)

## üìä Performance

### Compara√ß√£o CPU vs GPU

| M√©trica | CPU (Intel i5) | GPU (RTX 4060) | Melhoria |
|---------|----------------|----------------|----------|
| Tempo de Resposta | 30-60 segundos | 2-5 segundos | **10x mais r√°pido** |
| Tokens/segundo | ~5-10 | ~50-100 | **10x mais eficiente** |
| Uso de Mem√≥ria | 8GB RAM | 8GB RAM + 8GB VRAM | Melhor distribui√ß√£o |
| Temperatura | 70-80¬∞C | 45-55¬∞C | Mais eficiente |

### An√°lise de Custo-Benef√≠cio

- **Investimento**: RTX 4060 (~R$ 2.500)
- **Economia**: N√£o precisa de servi√ßos cloud caros
- **Privacidade**: Dados ficam na rede local
- **Velocidade**: 10x mais r√°pido que CPU
- **ROI**: Pago em 6-12 meses vs servi√ßos cloud

## üõ†Ô∏è Manuten√ß√£o

### Logs

```bash
# Ver logs do chatbot
docker-compose logs chatbot

# Ver logs do Ollama
docker-compose logs ollama

# Logs de chat
tail -f logs/chat_history.json
```

### Backup

```bash
# Backup dos modelos
sudo docker run --rm -v ollama_data:/root/.ollama -v $(pwd):/backup alpine tar czf /backup/ollama-models-$(date +%Y%m%d).tar.gz -C /root/.ollama .

# Backup de PDFs e cache
tar czf backup-pdfs-$(date +%Y%m%d).tar.gz uploads/ cache/
```

### Limpeza

```bash
# Limpar cache de PDFs
rm -rf cache/*

# Limpar uploads
rm -rf uploads/*

# Limpar logs antigos
find logs/ -name "*.json" -mtime +30 -delete
```

## üîç Troubleshooting

### Problemas Comuns

1. **GPU n√£o detectada**:
   ```bash
   nvidia-smi  # Verificar se GPU est√° funcionando
   sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
   ```

2. **Modelo n√£o baixa**:
   ```bash
   # Verificar espa√ßo em disco
   df -h
   
   # Verificar logs do Ollama
   docker-compose logs ollama
   ```

3. **PDF n√£o processa**:
   ```bash
   # Verificar depend√™ncias
   docker-compose exec chatbot pip list | grep -E "(PyPDF2|pdfplumber)"
   
   # Verificar logs
   docker-compose logs chatbot
   ```

4. **Interface n√£o carrega**:
   ```bash
   # Verificar se porta est√° livre
   netstat -tlnp | grep 8080
   
   # Reiniciar servi√ßos
   docker-compose restart
   ```

### Logs Detalhados

```bash
# Ativar logs detalhados
docker-compose up -d --build
docker-compose logs -f chatbot
```

## ü§ù Contribui√ß√£o

Para contribuir com o projeto:

1. Fork o reposit√≥rio
2. Crie uma branch para sua feature
3. Fa√ßa commit das mudan√ßas
4. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üôè Agradecimentos

- **Ollama**: Framework de IA local
- **Flask**: Framework web
- **NVIDIA**: Suporte a GPU
- **Comunidade Portal Sem Porteiras**: Testes e feedback

## üìû Suporte

Para suporte t√©cnico ou d√∫vidas:

- **Email**: suporte@portalsemporteiras.org
- **Telegram**: @portalsemporteiras
- **Issues**: GitHub Issues

---

**Desenvolvido com ‚ù§Ô∏è para a Rede Comunit√°ria Portal Sem Porteiras** 