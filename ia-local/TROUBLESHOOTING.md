# ðŸ› Guia de SoluÃ§Ã£o de Problemas

Este guia documenta problemas comuns e suas soluÃ§Ãµes baseadas em experiÃªncias reais.

## âš ï¸ Problemas Comuns

### 1. **Sistema entra em suspensÃ£o durante instalaÃ§Ã£o**

**Problema**: Servidor suspende no meio da instalaÃ§Ã£o via SSH

**Sintomas**:
- ConexÃ£o SSH cai
- Script para de responder
- Mensagem "The system will suspend now!"

**SoluÃ§Ãµes**:

#### OpÃ§Ã£o A: Desabilitar suspensÃ£o automÃ¡tica
```bash
# Desabilitar suspensÃ£o do sistema
sudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target

# Verificar se foi desabilitado
sudo systemctl status sleep.target
```

#### OpÃ§Ã£o B: Usar screen (Recomendado)
```bash
# Instalar screen
sudo apt install screen

# Criar uma nova sessÃ£o
screen -S instalacao

# Executar o script dentro do screen
./install-debian.sh
```

**Se a sessÃ£o cair, reconecte com:**
```bash
screen -r instalacao
```

#### OpÃ§Ã£o C: Usar nohup
```bash
# Executar em background que continua mesmo se SSH cair
nohup ./install-debian.sh > instalacao.log 2>&1 &

# Acompanhar o progresso
tail -f instalacao.log
```

### 2. **Script trava na instalaÃ§Ã£o do NVIDIA Container Toolkit**

**Problema**: Script para de responder durante instalaÃ§Ã£o dos drivers NVIDIA

**Sintomas**:
- Script para em "Instalando NVIDIA Container Toolkit..."
- NÃ£o responde a Ctrl+C
- Processo fica travado

**SoluÃ§Ã£o**:
```bash
# Parar processo travado
pkill -f install-debian

# Verificar se Docker jÃ¡ foi instalado
docker --version
docker-compose --version

# Se Docker estiver OK, continuar manualmente
git clone https://github.com/hiurequeiroz/GuiaServidorLocal.git
cd GuiaServidorLocal/ia-local
./start.sh
```

### 3. **Erro "Erro na comunicaÃ§Ã£o com o modelo de IA"**

**Problema**: Chatbot inicia mas nÃ£o consegue se comunicar com a IA

**Sintomas**:
- Interface web carrega
- Erro 500 ao tentar enviar mensagem
- Console mostra "Erro na comunicaÃ§Ã£o com o modelo de IA"

**Causa**: Modelo de IA nÃ£o foi baixado ainda

**SoluÃ§Ã£o**:
```bash
# Verificar se Ollama estÃ¡ funcionando
curl http://SEU_IP:11434/api/tags

# Baixar um modelo (pode demorar 10-15 minutos)
docker exec -it ia-local-ollama ollama pull llama2

# Verificar modelos disponÃ­veis
docker exec -it ia-local-ollama ollama list

# Testar API diretamente
curl -X POST http://SEU_IP:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama2", "prompt": "OlÃ¡"}'
```

### 4. **Container nÃ£o encontrado**

**Problema**: `Error: No such container: ia-local-ollama`

**Sintomas**:
- Comando docker exec falha
- Container nÃ£o aparece na lista

**SoluÃ§Ã£o**:
```bash
# Verificar containers ativos
docker ps

# Se nÃ£o estiver rodando, iniciar
cd GuiaServidorLocal/ia-local
./start.sh

# Verificar logs
docker-compose logs -f
```

### 5. **Download do modelo muito lento**

**Problema**: Download do modelo demora muito ou para

**Sintomas**:
- Progresso muito lento
- Download para no meio
- ConexÃ£o instÃ¡vel

**SoluÃ§Ãµes**:

#### Usar modelo menor
```bash
# Baixar modelo menor (mais rÃ¡pido)
docker exec -it ia-local-ollama ollama pull mistral
```

#### Verificar conexÃ£o
```bash
# Testar velocidade de download
wget --report-speed=bits https://speed.cloudflare.com/__down

# Verificar se hÃ¡ proxy ou firewall
curl -I https://ollama.ai
```

## ðŸ“‹ Checklist de VerificaÃ§Ã£o

ApÃ³s a instalaÃ§Ã£o, execute este checklist:

```bash
echo "=== VERIFICAÃ‡ÃƒO COMPLETA ==="
echo "Docker: $(docker --version)"
echo "Docker Compose: $(docker-compose --version)"
echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null || echo 'CPU apenas')"
echo "UsuÃ¡rio no grupo docker: $(groups $USER | grep docker && echo 'SIM' || echo 'NÃƒO')"
echo "Ollama API: $(curl -s http://localhost:11434/api/tags | grep -o '"models":\[.*\]' || echo 'NÃƒO RESPONDE')"
echo "Containers ativos: $(docker ps --format 'table {{.Names}}\t{{.Status}}')"
```

## ðŸ”§ Comandos Ãšteis

### Verificar status
```bash
# Status dos containers
docker-compose ps

# Logs em tempo real
docker-compose logs -f

# Uso da GPU
watch -n 1 nvidia-smi

# Uso de recursos
htop
```

### Reiniciar serviÃ§os
```bash
# Reiniciar containers
docker-compose restart

# Reiniciar Docker
sudo systemctl restart docker

# Reiniciar tudo
docker-compose down && ./start.sh
```

### Limpar e reinstalar
```bash
# Parar tudo
docker-compose down

# Remover imagens
docker rmi ia-local-web ollama/ollama

# Reinstalar
./start.sh
```

## ðŸ“ž Suporte

Se ainda tiver problemas:

1. **Verificar logs**: `docker-compose logs -f`
2. **Reiniciar**: `docker-compose restart`
3. **Reinstalar**: `./start.sh --reset`
4. **Verificar requisitos**: CPU 4 cores, RAM 8GB, 10GB livre

## ðŸŽ¯ Dicas Importantes

- **Sempre use screen** quando instalar via SSH
- **Baixe o modelo** antes de testar o chatbot
- **Verifique a GPU** se tiver placa NVIDIA
- **Monitore os logs** para identificar problemas
- **Use modelos menores** se tiver conexÃ£o lenta

---

**Baseado em experiÃªncias reais de instalaÃ§Ã£o** ðŸš€ 